# ==========================================
# ‚öôÔ∏è Infrastructure & Services
# ==========================================

# Qdrant URL
# Use "http://localhost:6333" if running scripts locally
# Use "http://qdrant:6333" if running inside Docker network
QDRANT_URL="http://localhost:6333"
QDRANT_COLLECTION="technical_support"

# Path to the knowledge base JSON (Local path)
DATA_PATH="data/knowledge_base.json"

# Triton Server URL (for Client)
TRITON_URL="localhost:8000"
TRITON_MODEL_NAME="bls_orchestrator"

# ==========================================
# üß† Models Configuration
# ==========================================

# --- Embeddings (SentenceTransformers) ---
EMBEDDING_MODEL_ID="sentence-transformers/all-MiniLM-L6-v2"
EMBEDDING_DEVICE="cuda"
# Path where ONNX model will be exported
EMBEDDING_OUTPUT_DIR="model_repository/embedding_onnx/1"

# --- YOLO (Vision Guardrail) ---
YOLO_MODEL_NAME="yolov8n"
# Path where ONNX model will be exported
YOLO_EXPORT_PATH="model_repository/yolo_onnx/1/model.onnx"
YOLO_TRITON_MODEL_NAME="yolo_onnx"
YOLO_IMAGE_SIZE="640"

# --- Reranker (Cross-Encoder) ---
RERANKER_MODEL_ID="cross-encoder/ms-marco-MiniLM-L-6-v2"
RERANKER_TRITON_MODEL_NAME="reranker_py"

# --- LLM (vLLM) ---
LLM_MODEL_ID="Qwen/Qwen3-30B-A3B-Instruct-2507"
LLM_TRITON_MODEL_NAME="llm_vllm"

# Generation Parameters
LLM_TEMPERATURE="0.1"
LLM_MAX_TOKENS="512"
LLM_TOP_P="0.95"

# ==========================================
# üîß System
# ==========================================
LOG_LEVEL="INFO"